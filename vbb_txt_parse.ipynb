{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "897fdb6c",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e734dc4",
   "metadata": {},
   "source": [
    "changes I've made:\n",
    "had to implement a yaml file and extract the data neccessary\n",
    "the file structure for both the jpeg and the txt were wrong so those had to be changed\n",
    "the naming for both the jpegs and the txt were wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5143b691",
   "metadata": {},
   "source": [
    "Create the dir names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76687a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data_folder_dir = \"C:/Users/dasul/Downloads/data_and_labels\" # this is just the name of the folder of where all the downloaded data is, jsut enter where its stored, and remeber to use forward slashes\n",
    "converted_data_dir = os.path.join(data_folder_dir, 'processed_data')\n",
    "converted_images_dir = os.path.join(converted_data_dir, 'images')\n",
    "converted_labels_dir = os.path.join(converted_data_dir, 'labels')\n",
    "converted_images_train_dir = os.path.join(converted_images_dir, 'train')\n",
    "converted_images_test_dir = os.path.join(converted_images_dir, 'test')\n",
    "converted_labels_train_dir = os.path.join(converted_labels_dir, 'train')\n",
    "converted_labels_test_dir = os.path.join(converted_labels_dir, 'test')\n",
    "os.makedirs(converted_data_dir, exist_ok=True)\n",
    "os.makedirs(converted_images_dir, exist_ok=True)\n",
    "os.makedirs(converted_labels_dir, exist_ok=True)\n",
    "os.makedirs(converted_images_train_dir, exist_ok=True)\n",
    "os.makedirs(converted_images_test_dir, exist_ok=True)\n",
    "os.makedirs(converted_labels_train_dir, exist_ok=True)\n",
    "os.makedirs(converted_labels_test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10423405",
   "metadata": {},
   "source": [
    "Create the Seq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46e7d639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting train frames: 100%|██████████| 71/71 [31:09<00:00, 26.33s/it]\n",
      "Extracting test frames: 100%|██████████| 66/66 [29:36<00:00, 26.92s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# base path = data_foler_dir\n",
    "base_path = data_folder_dir\n",
    "train_seq_files = glob(os.path.join(base_path, \"Train\", \"set*\", \"set*\", \"V*.seq\"))\n",
    "test_seq_files = glob(os.path.join(base_path, \"Test\", \"set*\", \"set*\", \"V*.seq\"))\n",
    "\n",
    "# img num will just be used to name the file, could potential cause issues, if the files are not processed in the same order ie vbb and seq\n",
    "def extract_frames_from_seq(seq_file, output_dir, imgnum):\n",
    "    #os.makedirs(output_dir, exist_ok=True)\n",
    "    # i commented out the previous file becuase i already created teh file\n",
    "    cap = cv2.VideoCapture(seq_file)\n",
    "    count = 0\n",
    "    base_name = os.path.splitext(os.path.basename(seq_file))[0]\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # *********** Filtering invalid/small frames ***********\n",
    "        if frame is None or frame.shape[0] < 100 or frame.shape[1] < 100:\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "        # *********** Resize image to YOLO-compatible size ***********\n",
    "        frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "        #filename = os.path.join(output_dir, f\"img{imgnum}.jpg\")\n",
    "        filename = os.path.join(output_dir, f\"{base_name}_{count:05d}.jpg\")\n",
    "        cv2.imwrite(filename, frame)\n",
    "        count += 1\n",
    "        imgnum += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "imgnum = 0\n",
    "# Extract train\n",
    "for seq_file in tqdm(train_seq_files, desc=\"Extracting train frames\"):\n",
    "    extract_frames_from_seq(seq_file, os.path.join(base_path, converted_images_train_dir), imgnum)\n",
    "\n",
    "# Extract tests\n",
    "for seq_file in tqdm(test_seq_files, desc=\"Extracting test frames\"):\n",
    "    extract_frames_from_seq(seq_file, os.path.join(base_path, converted_images_test_dir), imgnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75414ba9",
   "metadata": {},
   "source": [
    "Convert VBB to Txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e50d1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V000.vbb\n",
      "Done. 1845 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V001.vbb\n",
      "Done. 1844 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V002.vbb\n",
      "Done. 1322 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V003.vbb\n",
      "Done. 568 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V004.vbb\n",
      "Done. 2133 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V005.vbb\n",
      "Done. 2133 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V006.vbb\n",
      "Done. 1930 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V007.vbb\n",
      "Done. 1929 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V008.vbb\n",
      "Done. 1703 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V009.vbb\n",
      "Done. 1702 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V010.vbb\n",
      "Done. 1702 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V011.vbb\n",
      "Done. 1589 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V012.vbb\n",
      "Done. 1691 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V013.vbb\n",
      "Done. 1691 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set00\\V014.vbb\n",
      "Done. 1911 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set01\\V000.vbb\n",
      "Done. 1711 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set01\\V001.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set01\\V002.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set01\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set01\\V004.vbb\n",
      "Done. 1814 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set01\\V005.vbb\n",
      "Done. 1814 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V000.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V001.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V002.vbb\n",
      "Done. 1749 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V003.vbb\n",
      "Done. 1955 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V004.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V005.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V008.vbb\n",
      "Done. 1960 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V009.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V010.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set02\\V011.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V000.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V001.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V002.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V004.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V005.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V008.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V009.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V010.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V011.vbb\n",
      "Done. 1844 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set03\\V012.vbb\n",
      "Done. 1844 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V000.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V001.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V002.vbb\n",
      "Done. 1812 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V003.vbb\n",
      "Done. 1811 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V004.vbb\n",
      "Done. 1886 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V005.vbb\n",
      "Done. 1696 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V008.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V009.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V010.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set04\\V011.vbb\n",
      "Done. 1899 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V000.vbb\n",
      "Done. 1737 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V001.vbb\n",
      "Done. 1961 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V002.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V004.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V005.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V008.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V009.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V010.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V011.vbb\n",
      "Done. 1707 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set05\\V012.vbb\n",
      "Done. 1707 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\train\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V000.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V001.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V002.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V004.vbb\n",
      "Done. 1977 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V005.vbb\n",
      "Done. 2175 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V008.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V009.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V010.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set07\\V011.vbb\n",
      "Done. 1800 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V000.vbb\n",
      "Done. 1785 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V001.vbb\n",
      "Done. 1785 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V002.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V004.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V005.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V008.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V009.vbb\n",
      "Done. 1680 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set08\\V010.vbb\n",
      "Done. 1681 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V000.vbb\n",
      "Done. 1865 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V001.vbb\n",
      "Done. 1865 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V002.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V004.vbb\n",
      "Done. 1798 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V005.vbb\n",
      "Done. 1988 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V006.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V008.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V009.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V010.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set09\\V011.vbb\n",
      "Done. 1869 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V000.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V001.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V002.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V003.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V004.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V005.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V006.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V007.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V008.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V009.vbb\n",
      "Done. 1842 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V010.vbb\n",
      "Done. 1841 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n",
      "Reading .vbb file: C:/Users/dasul/Downloads/data_and_labels\\annotations/annotations/set10\\V011.vbb\n",
      "Done. 1734 label files saved in:\n",
      "C:\\Users\\dasul\\Downloads\\data_and_labels\\processed_data\\labels\\test\n"
     ]
    }
   ],
   "source": [
    "def convert_vbb_to_yolo(vbb_path, output_dir, setnum, vbbnum, image_width=640, image_height=480):\n",
    "    print(f\"Reading .vbb file: {vbb_path}\")\n",
    "    vbb = loadmat(vbb_path)\n",
    "    obj_lists = vbb['A'][0][0][1][0]  # objLists\n",
    "    n_frames = vbb['A'][0][0][0][0][0]  # nFrame\n",
    "\n",
    "\n",
    "    abs_output_dir = os.path.abspath(output_dir)\n",
    "    os.makedirs(abs_output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    for frame_idx in range(n_frames):\n",
    "        if obj_lists[frame_idx].size == 0:\n",
    "           objs = []\n",
    "        else:\n",
    "           objs = obj_lists[frame_idx][0]\n",
    "\n",
    "\n",
    "        label_lines = []\n",
    "\n",
    "\n",
    "        for obj in objs:\n",
    "            pos = obj[1][0]  # [x, y, w, h]\n",
    "            x, y, w, h = pos\n",
    "\n",
    "\n",
    "            # Convert to YOLO format (center x/y, normalized)\n",
    "            x_center = (x + w / 2) / image_width\n",
    "            y_center = (y + h / 2) / image_height\n",
    "            w_norm = w / image_width\n",
    "            h_norm = h / image_height\n",
    "\n",
    "\n",
    "            label_lines.append(f\"0 {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "\n",
    "\n",
    "        txt_path = os.path.join(abs_output_dir, f\"V{setnum:03d}_{vbbnum:05d}.txt\")\n",
    "        with open(txt_path, 'w') as f:\n",
    "            f.write('\\n'.join(label_lines))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Done. {n_frames} label files saved in:\\n{abs_output_dir}\")\n",
    "\n",
    "imgnumtxt = 0\n",
    "NUMBER_TRAIN_SETS = 6\n",
    "NUMBER_TEST_SETS = 5\n",
    "for s in range(NUMBER_TRAIN_SETS):\n",
    "    vbb_set_dir = os.path.join(data_folder_dir, f'annotations/annotations/set{s:02d}')\n",
    "    vbb_files = os.listdir(vbb_set_dir) # number of vbb files in each set\n",
    "    NUMBER_OF_VB = len(vbb_files)\n",
    "    #print(NUMBER_OF_VB)\n",
    "    for v in range(NUMBER_OF_VB):\n",
    "        # dont need to change this dir\n",
    "        vbb_path = os.path.join(vbb_set_dir, f'V{v:03d}.vbb') \n",
    "        convert_vbb_to_yolo(vbb_path, converted_labels_train_dir, s, v, image_width=640, image_height=480)\n",
    "\n",
    "for s in range(NUMBER_TRAIN_SETS+1, NUMBER_TRAIN_SETS + NUMBER_TEST_SETS):\n",
    "    vbb_set_dir = os.path.join(data_folder_dir, f'annotations/annotations/set{s:02d}')\n",
    "    vbb_files = os.listdir(vbb_set_dir) # number of vbb files in each set\n",
    "    NUMBER_OF_VB = len(vbb_files)\n",
    "    #print(NUMBER_OF_VB)\n",
    "    for v in range(NUMBER_OF_VB):\n",
    "        # dont need to change this dir\n",
    "        vbb_path = os.path.join(vbb_set_dir, f'V{v:03d}.vbb') \n",
    "        convert_vbb_to_yolo(vbb_path, converted_labels_test_dir, s, v, image_width=640, image_height=480)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66154847",
   "metadata": {},
   "source": [
    "Create the YAML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38c182a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.yaml created successfully!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "data = {\n",
    "    'train': converted_images_train_dir,\n",
    "    'val': converted_images_test_dir,\n",
    "    'nc': 1,\n",
    "    'names': ['pedestrian']\n",
    "}\n",
    "\n",
    "yaml_dir = os.path.join(converted_data_dir, 'data.yaml')\n",
    "with open(yaml_dir, 'w') as file:\n",
    "    yaml.dump(data, file, default_flow_style=False)\n",
    "\n",
    "print(\"data.yaml created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aac8dd",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69084d0b",
   "metadata": {},
   "source": [
    "idk why this was so buggy, I had to inlcude the absolute path for the model becuase otherwise it would just not recognise the yaml file\n",
    "another error i got was in the line: img = torch.tensor(img).float() / 255.0, and i got a value error, becaus ethe numpy array had negative strides, and we were trying to convert into a pytorch tensor, so i replaced the line with:\n",
    "img = torch.tensor(img.copy()).float() / 255.0, which was an edit to the custom_yolo_dataset file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1825f",
   "metadata": {},
   "source": [
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77072982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  yolov5.models.common.Conv               [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2                -1  1     18816  yolov5.models.common.C3                 [64, 64, 1]                   \n",
      "  3                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  yolov5.models.common.C3                 [128, 128, 2]                 \n",
      "  5                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  yolov5.models.common.C3                 [256, 256, 3]                 \n",
      "  7                -1  1   1180672  yolov5.models.common.Conv               [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1]                 \n",
      "  9                -1  1    656896  yolov5.models.common.SPPF               [512, 512, 5]                 \n",
      " 10                -1  1    131584  yolov5.models.common.Conv               [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
      " 13                -1  1    361984  yolov5.models.common.C3                 [512, 256, 1, False]          \n",
      " 14                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
      " 17                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
      " 18                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
      " 20                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
      " 21                -1  1    590336  yolov5.models.common.Conv               [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
      " 23                -1  1   1182720  yolov5.models.common.C3                 [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  yolov5.models.yolo.Detect               [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 71\u001b[39m\n\u001b[32m     68\u001b[39m imgs = imgs.to(device)\n\u001b[32m     69\u001b[39m targets = [t.to(device) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets] \u001b[38;5;66;03m# also had to make an edit here\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m preds = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mhere\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     73\u001b[39m loss = yolo_loss(preds, targets)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\yolov5\\models\\yolo.py:209\u001b[39m, in \u001b[36mDetectionModel.forward\u001b[39m\u001b[34m(self, x, augment, profile, visualize)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_augment(x)  \u001b[38;5;66;03m# augmented inference, None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_forward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\yolov5\\models\\yolo.py:121\u001b[39m, in \u001b[36mBaseModel._forward_once\u001b[39m\u001b[34m(self, x, profile, visualize)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28mself\u001b[39m._profile_one_layer(m, x, dt)\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m x = \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[32m    122\u001b[39m y.append(x \u001b[38;5;28;01mif\u001b[39;00m m.i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.save \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\yolov5\\models\\common.py:234\u001b[39m, in \u001b[36mSPPF.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    232\u001b[39m y1 = \u001b[38;5;28mself\u001b[39m.m(x)\n\u001b[32m    233\u001b[39m y2 = \u001b[38;5;28mself\u001b[39m.m(y1)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\yolov5\\models\\common.py:57\u001b[39m, in \u001b[36mConv.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.act(\u001b[38;5;28mself\u001b[39m.bn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dasul\\156\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# train.py\n",
    "# Custom training script for YOLOv5 pedestrian detection project\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'yolov5'))\n",
    "from yolov5.models.yolo import Model\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'custom_yolo_dataset'))\n",
    "from custom_yolo_dataset import YOLODataset\n",
    "\n",
    "# Device setup \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the YOLOv5 small model architecture (1 class = person)\n",
    "# idk but this part wasnt working as it was so I used the absolute path\n",
    "cfg_path = \"C:/Users/dasul/156/yolov5/models/yolov5s.yaml\"\n",
    "model = Model(cfg=cfg_path, ch=3, nc=1).to(device)\n",
    "\n",
    "# Initialize weights for better training\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Set image resolution to higher value for small object detection (e.g. pedestrians)\n",
    "img_size = 640\n",
    "\n",
    "# Load training data using our custom dataset class\n",
    "train_dataset = YOLODataset(\n",
    "    images_dir= converted_images_train_dir,\n",
    "    labels_dir= converted_labels_train_dir,\n",
    "    img_size=img_size\n",
    ")\n",
    "\n",
    "## had to add this functino as well to deal with the fact that we were getting tensors of different size, and added it to trainloader and targets\n",
    "def yolo_collate_fn(batch):\n",
    "    images, labels = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    return images, labels\n",
    "\n",
    "# Wrap the dataset in a DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=yolo_collate_fn)\n",
    "\n",
    "# Set up optimizer and learning rate scheduler (with decay)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)  # LR halves every 3 epochs\n",
    "\n",
    "# Simple placeholder loss \n",
    "def yolo_loss(pred, targets):\n",
    "    return pred[0].sum() * 0.0  # dummy loss, for structure only\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, targets in train_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        targets = [t.to(device) for t in targets] # also had to make an edit here\n",
    "\n",
    "        preds = model(imgs)\n",
    "        print(\"here\")\n",
    "        loss = yolo_loss(preds, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()  # apply learning rate decay\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "    print(f\"completed epoch {epoch+1}/{epoch}\")\n",
    "\n",
    "# Save the trained model weights\n",
    "torch.save(model.state_dict(), 'best.pt')\n",
    "print(\"Training complete. Weights saved as best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38015916",
   "metadata": {},
   "source": [
    "# Analysing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992b7a47",
   "metadata": {},
   "source": [
    "some additional changes ive made:\n",
    "so for some reason you need to include the absolute path to the model otherwise it wont detect so this is gonna be speicifc to whoever is running the program\n",
    "also had the same problme with converting numpy array to pytorch, this time making a copy of images was enoguh ie images.copy() instead of just converting images\n",
    "Also edited some of the file location and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d348b70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/dasul/156/yolov5\\utils\\general.py:32: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources as pkg\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "saved\n",
      "\n",
      "✅ Inference complete. Results saved to 'inference_output/'\n",
      "🔍 Precision: 0.0001\n",
      "📦 Recall:    1.0000\n",
      "TP: 65, FP: 652435, FN: 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# so now I need to create a an array of the predicted values vs the target values\n",
    "# well the target values are held in \n",
    "\n",
    "# infer.py\n",
    "# Custom inference script with annotation saving + precision/recall evaluation\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('C:/Users/dasul/156/yolov5')\n",
    "#sys.path.append(os.path.join(os.getcwd(), 'yolov5'))\n",
    "from models.yolo import Model\n",
    "from yolov5.utils.general import non_max_suppression, scale_boxes\n",
    "from yolov5.utils.augmentations import letterbox\n",
    "#from yolov5.utils.plots import plot_one_box\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load YOLOv5 model architecture and trained weights\n",
    "cfg_path = 'C:/Users/dasul/156/yolov5/models/yolov5s.yaml'\n",
    "model = Model(cfg=cfg_path, ch=3, nc=1).to(device)\n",
    "model.load_state_dict(torch.load('best.pt', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Input and output paths\n",
    "image_dir = converted_images_test_dir\n",
    "gt_label_dir = converted_labels_test_dir\n",
    "results_dir = os.path.join(data_folder_dir, 'results')\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "output_img_dir = os.path.join(results_dir, 'inference_output/images')\n",
    "output_txt_dir = os.path.join(results_dir, 'inference_output/labels')\n",
    "os.makedirs(output_img_dir, exist_ok=True)\n",
    "os.makedirs(output_txt_dir, exist_ok=True)\n",
    "\n",
    "# Inference settings\n",
    "img_size = 640\n",
    "conf_thres = 0.5\n",
    "iou_thres = 0.45\n",
    "\n",
    "# Initialize counters\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "def plot_one_box(xyxy, img, color=(0, 255, 0), label=None, line_thickness=2):\n",
    "    \"\"\"\n",
    "    Draws a bounding box with optional label on an image.\n",
    "\n",
    "    Args:\n",
    "        xyxy (list): [x1, y1, x2, y2]\n",
    "        img (ndarray): Image to draw on\n",
    "        color (tuple): BGR box color\n",
    "        label (str): Optional label text\n",
    "        line_thickness (int): Box line thickness\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), color, thickness=line_thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "    if label:\n",
    "        font_scale = 0.5\n",
    "        font_thickness = 1\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)[0]\n",
    "        c2 = x1 + t_size[0], y1 - t_size[1] - 3\n",
    "        cv2.rectangle(img, (x1, y1), c2, color, -1, cv2.LINE_AA)\n",
    "        cv2.putText(img, label, (x1, y1 - 2), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    font_scale, (255, 255, 255), font_thickness, lineType=cv2.LINE_AA)\n",
    "\n",
    "# Helper functions\n",
    "def compute_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    if inter_area == 0:\n",
    "        return 0.0\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    return inter_area / (box1_area + box2_area - inter_area)\n",
    "\n",
    "def load_ground_truth(txt_path, img_shape):\n",
    "    h, w = img_shape\n",
    "    boxes = []\n",
    "    if not os.path.exists(txt_path):\n",
    "        return boxes\n",
    "    with open(txt_path, 'r') as f:\n",
    "        for line in f:\n",
    "            cls, x, y, bw, bh = map(float, line.strip().split())\n",
    "            x1 = (x - bw / 2) * w\n",
    "            y1 = (y - bh / 2) * h\n",
    "            x2 = (x + bw / 2) * w\n",
    "            y2 = (y + bh / 2) * h\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "    return boxes\n",
    "\n",
    "# Inference loop\n",
    "for filename in os.listdir(image_dir):\n",
    "    if not filename.endswith('.jpg'):\n",
    "        continue\n",
    "\n",
    "    img_path = os.path.join(image_dir, filename)\n",
    "    img0 = cv2.imread(img_path)\n",
    "    h0, w0 = img0.shape[:2]\n",
    "    img = letterbox(img0, new_shape=img_size)[0]\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)\n",
    "    img = torch.from_numpy(img.copy()).float() / 255.0\n",
    "    img = img.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img)\n",
    "        pred = non_max_suppression(pred, conf_thres=conf_thres, iou_thres=iou_thres)\n",
    "\n",
    "    label_lines = []\n",
    "    matched = set()\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    gt_boxes = load_ground_truth(os.path.join(gt_label_dir, base_name + \".txt\"), (h0, w0))\n",
    "\n",
    "    for det in pred:\n",
    "        if det is not None and len(det):\n",
    "            det[:, :4] = scale_boxes(img.shape[2:], det[:, :4], img0.shape).round()\n",
    "            for *xyxy, conf, cls in det:\n",
    "                x1, y1, x2, y2 = [coord.item() for coord in xyxy]\n",
    "                plot_one_box([x1, y1, x2, y2], img0, label=f\"person {conf:.2f}\")\n",
    "\n",
    "                # YOLO-format normalized box\n",
    "                x_center = ((x1 + x2) / 2) / w0\n",
    "                y_center = ((y1 + y2) / 2) / h0\n",
    "                bw = (x2 - x1) / w0\n",
    "                bh = (y2 - y1) / h0\n",
    "                label_lines.append(f\"0 {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\") \n",
    "\n",
    "                # Compare with ground truth for precision\n",
    "                found_match = False\n",
    "                for i, gt in enumerate(gt_boxes):\n",
    "                    iou = compute_iou([x1, y1, x2, y2], gt)\n",
    "                    if iou > 0.5 and i not in matched:\n",
    "                        tp += 1\n",
    "                        matched.add(i)\n",
    "                        found_match = True\n",
    "                        break\n",
    "                if not found_match:\n",
    "                    fp += 1\n",
    "        else:\n",
    "            if len(gt_boxes) > 0:\n",
    "                fn += len(gt_boxes)\n",
    "\n",
    "    # Save annotated image\n",
    "    cv2.imwrite(os.path.join(output_img_dir, filename), img0)\n",
    "    print(\"saved\")\n",
    "\n",
    "    # Save YOLO label txt\n",
    "    with open(os.path.join(output_txt_dir, base_name + \".txt\"), 'w') as f:\n",
    "        f.write('\\n'.join(label_lines))\n",
    "\n",
    "# Compute and print precision/recall\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "print(f\"\\n✅ Inference complete. Results saved to 'inference_output/'\")\n",
    "print(f\"🔍 Precision: {precision:.4f}\")\n",
    "print(f\"📦 Recall:    {recall:.4f}\")\n",
    "print(f\"TP: {tp}, FP: {fp}, FN: {fn}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
